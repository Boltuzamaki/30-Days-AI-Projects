{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chose path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"C:\\\\Users\\\\boltuzamaki\\\\Desktop\\\\NLP\\\\aclImdb\\\\train\"\n",
    "save_path = \"C:\\\\Users\\\\boltuzamaki\\\\Desktop\\\\NLP\\\\aclImdb\"\n",
    "test_dir = \"C:\\\\Users\\\\boltuzamaki\\\\Desktop\\\\NLP\\\\aclImdb\\\\test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare dataset in form of CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which direct change all txt files along with labels to csv files\n",
    "\n",
    "review = []\n",
    "texts_n = []\n",
    "\n",
    "def txt_2_csv(path,type_s =\"train\"):\n",
    "    path_save = type_s+\".csv\"\n",
    "    os.chdir(train_dir)\n",
    "    list1 = os.listdir()\n",
    "    for l in list1:\n",
    "        os.chdir(train_dir+\"\\\\\"+l)\n",
    "        texts = os.listdir()\n",
    "        \n",
    "        for text in texts:\n",
    "            f = open(text, 'r', encoding=\"utf-8\")\n",
    "            new = f.read()\n",
    "            texts_n.append(new)\n",
    "            review.append(l)\n",
    "            f.close()\n",
    "        os.chdir(\"..\")   \n",
    "    # dictionary of lists  \n",
    "    dict = {'text': texts_n, 'review': review}  \n",
    "    df = pd.DataFrame(dict) \n",
    "    os.chdir(save_path)\n",
    "    # saving the dataframe \n",
    "    df.to_csv(path_save,index = None)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making CSV for train and testing \n",
    "\n",
    "txt_2_csv(train_dir)\n",
    "txt_2_csv(test_dir, type_s = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and text from created CSV\n",
    "\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film lacked something I couldn't put my f...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sorry everyone,,, I know this is supposed to b...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When I was little my parents took me along to ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text review\n",
       "0  Story of a man who has unnatural feelings for ...    neg\n",
       "1  Airport '77 starts as a brand new luxury 747 p...    neg\n",
       "2  This film lacked something I couldn't put my f...    neg\n",
       "3  Sorry everyone,,, I know this is supposed to b...    neg\n",
       "4  When I was little my parents took me along to ...    neg"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Airport '77 starts as a brand new luxury 747 plane is loaded up with valuable paintings & such belonging to rich businessman Philip Stevens (James Stewart) who is flying them & a bunch of VIP's to his estate in preparation of it being opened to the public as a museum, also on board is Stevens daughter Julie (Kathleen Quinlan) & her son. The luxury jetliner takes off as planned but mid-air the plane is hi-jacked by the co-pilot Chambers (Robert Foxworth) & his two accomplice's Banker (Monte Markham) & Wilson (Michael Pataki) who knock the passengers & crew out with sleeping gas, they plan to steal the valuable cargo & land on a disused plane strip on an isolated island but while making his descent Chambers almost hits an oil rig in the Ocean & loses control of the plane sending it crashing into the sea where it sinks to the bottom right bang in the middle of the Bermuda Triangle. With air in short supply, water leaking in & having flown over 200 miles off course the problems mount for the survivor's as they await help with time fast running out...<br /><br />Also known under the slightly different tile Airport 1977 this second sequel to the smash-hit disaster thriller Airport (1970) was directed by Jerry Jameson & while once again like it's predecessors I can't say Airport '77 is any sort of forgotten classic it is entertaining although not necessarily for the right reasons. Out of the three Airport films I have seen so far I actually liked this one the best, just. It has my favourite plot of the three with a nice mid-air hi-jacking & then the crashing (didn't he see the oil rig?) & sinking of the 747 (maybe the makers were trying to cross the original Airport with another popular disaster flick of the period The Poseidon Adventure (1972)) & submerged is where it stays until the end with a stark dilemma facing those trapped inside, either suffocate when the air runs out or drown as the 747 floods or if any of the doors are opened & it's a decent idea that could have made for a great little disaster flick but bad unsympathetic character's, dull dialogue, lethargic set-pieces & a real lack of danger or suspense or tension means this is a missed opportunity. While the rather sluggish plot keeps one entertained for 108 odd minutes not that much happens after the plane sinks & there's not as much urgency as I thought there should have been. Even when the Navy become involved things don't pick up that much with a few shots of huge ships & helicopters flying about but there's just something lacking here. George Kennedy as the jinxed airline worker Joe Patroni is back but only gets a couple of scenes & barely even says anything preferring to just look worried in the background.<br /><br />The home video & theatrical version of Airport '77 run 108 minutes while the US TV versions add an extra hour of footage including a new opening credits sequence, many more scenes with George Kennedy as Patroni, flashbacks to flesh out character's, longer rescue scenes & the discovery or another couple of dead bodies including the navigator. While I would like to see this extra footage I am not sure I could sit through a near three hour cut of Airport '77. As expected the film has dated badly with horrible fashions & interior design choices, I will say no more other than the toy plane model effects aren't great either. Along with the other two Airport sequels this takes pride of place in the Razzie Award's Hall of Shame although I can think of lots of worse films than this so I reckon that's a little harsh. The action scenes are a little dull unfortunately, the pace is slow & not much excitement or tension is generated which is a shame as I reckon this could have been a pretty good film if made properly.<br /><br />The production values are alright if nothing spectacular. The acting isn't great, two time Oscar winner Jack Lemmon has said since it was a mistake to star in this, one time Oscar winner James Stewart looks old & frail, also one time Oscar winner Lee Grant looks drunk while Sir Christopher Lee is given little to do & there are plenty of other familiar faces to look out for too.<br /><br />Airport '77 is the most disaster orientated of the three Airport films so far & I liked the ideas behind it even if they were a bit silly, the production & bland direction doesn't help though & a film about a sunken plane just shouldn't be this boring or lethargic. Followed by The Concorde ... Airport '79 (1979).\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"text\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Plotting number of counts of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_tags = ['pos','neg']\n",
    "plt.figure(figsize=(10,4))\n",
    "train_data.review.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Unigram_BOW(data):                                                                    # Convert to Unigram BOW model\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    bag_of_words = count_vectorizer.fit_transform(data)\n",
    "    return bag_of_words\n",
    "\n",
    "\n",
    "def stopwords_fun(text):                                                                   # Remove stopwords\n",
    "    stopword = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = []\n",
    "    for w in word_tokens:\n",
    "        if w not in stopword:\n",
    "            filtered_text.append(w)\n",
    "    filtered_text1 = ' '.join(filtered_text)        \n",
    "    return filtered_text1\n",
    "\n",
    "\n",
    "def Feature_extraction(grams = \"Uni\", tfidf = True,combined_data = None, data = \"train\"  ):  # Convert Bigram BOW models\n",
    "    if grams == \"Uni\":\n",
    "        count_vectorizer = CountVectorizer()\n",
    "        bow = count_vectorizer.fit(combined_data)\n",
    "        dataf = bow.transform(data) \n",
    "        if tfidf==True:\n",
    "            from sklearn.feature_extraction.text import TfidfTransformer \n",
    "            transformer = TfidfTransformer()\n",
    "            tf_bow = transformer.fit(dataf)\n",
    "            datat = tf_bow.transform(dataf)\n",
    "            \n",
    "    if grams == \"Bi\":\n",
    "        count_vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "        bow = count_vectorizer.fit(combined_data)\n",
    "        dataf = bow.transform(data) \n",
    "        if tfidf==True:\n",
    "            from sklearn.feature_extraction.text import TfidfTransformer \n",
    "            transformer = TfidfTransformer()\n",
    "            tf_bow = transformer.fit(dataf)\n",
    "            datat = tf_bow.transform(dataf)\n",
    "             \n",
    "    if grams == \"Tri\":\n",
    "        count_vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "        bow = count_vectorizer.fit(combined_data)\n",
    "        dataf = bow.transform(data)\n",
    "        if tfidf==True:\n",
    "            from sklearn.feature_extraction.text import TfidfTransformer \n",
    "            transformer = TfidfTransformer()\n",
    "            tf_bow = transformer.fit(dataf)\n",
    "            datat = tf_bow.transform(dataf)\n",
    "            \n",
    "    if tfidf == True:\n",
    "        return datat\n",
    "    if tfidf == False:\n",
    "        return dataf\n",
    "\n",
    "    \n",
    "def stochastic_descent(Xtrain, Ytrain, Xtest):                                                   # Stocastic Gradient Decent  \n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    parameters = {\"penalty\":['l2', 'l1', 'elasticnet'],\n",
    "                  \"max_iter\":[5,10,15]\n",
    "                  }\n",
    "    clf =  GridSearchCV(SGDClassifier(), parameters)\n",
    "    print (\"SGD(Linear Support Vector Machine) Fitting\")\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    print (\"SGD(Linear Support Vector Machine) Predicting\")\n",
    "    Ytest = clf.predict(Xtest)\n",
    "    return Ytest,clf\n",
    "\n",
    "def naive_bayes(Xtrain, Ytrain, Xtest):\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    clf = MultinomialNB()\n",
    "    print (\"Naive Bayes Fitting\")\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    print (\"SGD(Linear Support Vector Machine) Predicting\")\n",
    "    Ytest = clf.predict(Xtest)\n",
    "    return Ytest,clf\n",
    "\n",
    "def Logistic(Xtrain, Ytrain, Xtest):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    parameters = {\"penalty\":['l2', 'l1', 'elasticnet']\n",
    "                  }\n",
    "    clf =  GridSearchCV(LogisticRegression(), parameters)\n",
    "    print (\"Logistic Fitting\")\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    print (\"SLogistic Predicting\")\n",
    "    Ytest = clf.predict(Xtest)\n",
    "    return Ytest,clf\n",
    "    \n",
    "def accuracy(Ytrain, Ytest):                                                                       # Calculate accuracy\n",
    "    assert (len(Ytrain)==len(Ytest))\n",
    "    num =  sum([1 for i, word in enumerate(Ytrain) if Ytest[i]==word])\n",
    "    n = len(Ytrain)  \n",
    "    return (num*100)/n\n",
    "\n",
    "def remove_punct(data):                                                                           # Remove punctuation marks\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    token = word_tokenize(data)\n",
    "    words = [word for word in token if word.isalpha()]\n",
    "    words = ' '.join(words) \n",
    "    return words\n",
    "\n",
    "def remove_html_tag(data):\n",
    "    texts = [re.sub('<[^<]+?>', '', textl) for textl in data]\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make list of train and test text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train = train_data.text\n",
    "text_X = remove_html_tag(texts_train)\n",
    "texts_test = test_data.text\n",
    "text_Y = remove_html_tag(texts_test)\n",
    "review_train = train_data.review\n",
    "review_test = test_data.review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train_withoutstop = []\n",
    "\n",
    "for text in text_X:\n",
    "    sen = stopwords_fun(text)\n",
    "    sen = remove_punct(sen)\n",
    "    text_train_withoutstop.append(sen) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_test_withoutstop = []\n",
    "for text in text_Y:\n",
    "    sen = stopwords_fun(text)\n",
    "    sen = remove_punct(sen)\n",
    "    text_test_withoutstop.append(sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Categorical value to model feedable form change according to your need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = [1 if x==\"pos\" else 0 for x in review_test ]\n",
    "Y_train = [1 if x==\"pos\" else 0 for x in review_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining test and train data fro creating BOW and Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = text_test_withoutstop + text_train_withoutstop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Results For unigram without Tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Unigram BOW without Tfidf -->\n",
      "\n",
      "SGD(Linear Support Vector Machine) Fitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD(Linear Support Vector Machine) Predicting\n",
      "accuracy 91.472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.92      0.90      0.91     25000\n",
      "         neg       0.91      0.92      0.92     25000\n",
      "\n",
      "    accuracy                           0.91     50000\n",
      "   macro avg       0.91      0.91      0.91     50000\n",
      "weighted avg       0.91      0.91      0.91     50000\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Naive Bayes Fitting\n",
      "SGD(Linear Support Vector Machine) Predicting\n",
      "accuracy 91.044\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.89      0.94      0.91     25000\n",
      "         neg       0.93      0.89      0.91     25000\n",
      "\n",
      "    accuracy                           0.91     50000\n",
      "   macro avg       0.91      0.91      0.91     50000\n",
      "weighted avg       0.91      0.91      0.91     50000\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Logistic Fitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLogistic Predicting\n",
      "accuracy 99.788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       1.00      1.00      1.00     25000\n",
      "         neg       1.00      1.00      1.00     25000\n",
      "\n",
      "    accuracy                           1.00     50000\n",
      "   macro avg       1.00      1.00      1.00     50000\n",
      "weighted avg       1.00      1.00      1.00     50000\n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "print(\"For Unigram BOW without Tfidf -->\\n\")\n",
    "Uni_Bow_Tr = Feature_extraction(grams = \"Uni\", tfidf = False,combined_data = full_text,data = text_train_withoutstop ) \n",
    "Uni_Bow_Te = Feature_extraction(grams = \"Uni\", tfidf = False,combined_data = full_text,data = text_test_withoutstop ) \n",
    "\n",
    "Ytest_uni,clf1 = stochastic_descent(Uni_Bow_Tr, Y_train, Uni_Bow_Te)\n",
    "print('accuracy %s' % accuracy(Ytest_uni, Y_test))\n",
    "print(classification_report(Y_test, Ytest_uni,target_names=my_tags),\"\\n\\n\\n\")\n",
    "\n",
    "Ytest_uni,clf1 = naive_bayes(Uni_Bow_Tr, Y_train, Uni_Bow_Te)\n",
    "print('accuracy %s' % accuracy(Ytest_uni, Y_test))\n",
    "print(classification_report(Y_test, Ytest_uni,target_names=my_tags),\"\\n\\n\\n\")\n",
    "\n",
    "Ytest_uni,clf1 = Logistic(Uni_Bow_Tr, Y_train, Uni_Bow_Te)\n",
    "print('accuracy %s' % accuracy(Ytest_uni, Y_test))\n",
    "print(classification_report(Y_test, Ytest_uni,target_names=my_tags),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results For Bigram without Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Bigram BOW without Tfidf -->\n",
      "\n",
      "SGD(Linear Support Vector Machine) Fitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD(Linear Support Vector Machine) Predicting\n",
      "accuracy 99.992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       1.00      1.00      1.00     25000\n",
      "         neg       1.00      1.00      1.00     25000\n",
      "\n",
      "    accuracy                           1.00     50000\n",
      "   macro avg       1.00      1.00      1.00     50000\n",
      "weighted avg       1.00      1.00      1.00     50000\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Naive Bayes Fitting\n",
      "SGD(Linear Support Vector Machine) Predicting\n",
      "accuracy 99.792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       1.00      1.00      1.00     25000\n",
      "         neg       1.00      1.00      1.00     25000\n",
      "\n",
      "    accuracy                           1.00     50000\n",
      "   macro avg       1.00      1.00      1.00     50000\n",
      "weighted avg       1.00      1.00      1.00     50000\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Logistic Fitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLogistic Predicting\n",
      "accuracy 100.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       1.00      1.00      1.00     25000\n",
      "         neg       1.00      1.00      1.00     25000\n",
      "\n",
      "    accuracy                           1.00     50000\n",
      "   macro avg       1.00      1.00      1.00     50000\n",
      "weighted avg       1.00      1.00      1.00     50000\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"For Bigram BOW without Tfidf -->\\n\")\n",
    "Bi_Bow_Tr = Feature_extraction(grams = \"Bi\", tfidf = False,combined_data = full_text,data = text_train_withoutstop ) \n",
    "Bi_Bow_Te = Feature_extraction(grams = \"Bi\", tfidf = False,combined_data = full_text,data = text_test_withoutstop )\n",
    "\n",
    "Ytest_bi,clf1 = stochastic_descent(Bi_Bow_Tr, Y_train, Bi_Bow_Te)\n",
    "print('accuracy %s' % accuracy(Ytest_bi, Y_test))\n",
    "print(classification_report(Y_test, Ytest_bi,target_names=my_tags),\"\\n\\n\\n\")\n",
    "\n",
    "Ytest_bi,clf1 = naive_bayes(Bi_Bow_Tr, Y_train, Bi_Bow_Te)\n",
    "print('accuracy %s' % accuracy(Ytest_bi, Y_test))\n",
    "print(classification_report(Y_test, Ytest_bi,target_names=my_tags),\"\\n\\n\\n\")\n",
    "\n",
    "Ytest_bi,clf1 = Logistic(Bi_Bow_Tr, Y_train, Bi_Bow_Te)\n",
    "print('accuracy %s' % accuracy(Ytest_bi, Y_test))\n",
    "print(classification_report(Y_test, Ytest_bi,target_names=my_tags),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results For trigram without Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Trigram BOW without Tfidf -->\n",
      "\n",
      "SGD(Linear Support Vector Machine) Fitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD(Linear Support Vector Machine) Predicting\n",
      "accuracy 99.984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       1.00      1.00      1.00     25000\n",
      "         neg       1.00      1.00      1.00     25000\n",
      "\n",
      "    accuracy                           1.00     50000\n",
      "   macro avg       1.00      1.00      1.00     50000\n",
      "weighted avg       1.00      1.00      1.00     50000\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Naive Bayes Fitting\n",
      "SGD(Linear Support Vector Machine) Predicting\n",
      "accuracy 99.984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       1.00      1.00      1.00     25000\n",
      "         neg       1.00      1.00      1.00     25000\n",
      "\n",
      "    accuracy                           1.00     50000\n",
      "   macro avg       1.00      1.00      1.00     50000\n",
      "weighted avg       1.00      1.00      1.00     50000\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Logistic Fitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLogistic Predicting\n",
      "accuracy 100.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       1.00      1.00      1.00     25000\n",
      "         neg       1.00      1.00      1.00     25000\n",
      "\n",
      "    accuracy                           1.00     50000\n",
      "   macro avg       1.00      1.00      1.00     50000\n",
      "weighted avg       1.00      1.00      1.00     50000\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"For Trigram BOW without Tfidf -->\\n\")\n",
    "Tri_Bow_Tr = Feature_extraction(grams = \"Tri\", tfidf = False,combined_data = full_text,data = text_train_withoutstop )\n",
    "Tri_Bow_te = Feature_extraction(grams = \"Tri\", tfidf = False,combined_data = full_text,data = text_test_withoutstop )\n",
    "\n",
    "Ytest_tri,clf1 = stochastic_descent(Tri_Bow_Tr, Y_train, Tri_Bow_te)\n",
    "print('accuracy %s' % accuracy(Ytest_tri, Y_test))\n",
    "print(classification_report(Y_test, Ytest_tri,target_names=my_tags),\"\\n\\n\\n\")\n",
    "\n",
    "Ytest_tri,clf1 = naive_bayes(Tri_Bow_Tr, Y_train, Tri_Bow_te)\n",
    "print('accuracy %s' % accuracy(Ytest_tri, Y_test))\n",
    "print(classification_report(Y_test, Ytest_tri,target_names=my_tags),\"\\n\\n\\n\")\n",
    "\n",
    "Ytest_tri,clf1 = Logistic(Tri_Bow_Tr, Y_train, Tri_Bow_te)\n",
    "print('accuracy %s' % accuracy(Ytest_tri, Y_test))\n",
    "print(classification_report(Y_test, Ytest_tri,target_names=my_tags),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results For unigram with Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Unigram BOW with Tfidf -->\n",
      "\n",
      "SGD(Linear Support Vector Machine) Fitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD(Linear Support Vector Machine) Predicting\n",
      "accuracy 88.376\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.90      0.87      0.88     25000\n",
      "         neg       0.87      0.90      0.89     25000\n",
      "\n",
      "    accuracy                           0.88     50000\n",
      "   macro avg       0.88      0.88      0.88     50000\n",
      "weighted avg       0.88      0.88      0.88     50000\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Naive Bayes Fitting\n",
      "SGD(Linear Support Vector Machine) Predicting\n",
      "accuracy 91.428\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.90      0.93      0.92     25000\n",
      "         neg       0.92      0.90      0.91     25000\n",
      "\n",
      "    accuracy                           0.91     50000\n",
      "   macro avg       0.91      0.91      0.91     50000\n",
      "weighted avg       0.91      0.91      0.91     50000\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Logistic Fitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLogistic Predicting\n",
      "accuracy 93.524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.94      0.93      0.93     25000\n",
      "         neg       0.93      0.94      0.94     25000\n",
      "\n",
      "    accuracy                           0.94     50000\n",
      "   macro avg       0.94      0.94      0.94     50000\n",
      "weighted avg       0.94      0.94      0.94     50000\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"For Unigram BOW with Tfidf -->\\n\")\n",
    "Uni_Tf_Tr = Feature_extraction(grams = \"Uni\", tfidf = True,combined_data = full_text,data = text_train_withoutstop ) \n",
    "Uni_Tf_Te = Feature_extraction(grams = \"Uni\", tfidf = True,combined_data = full_text,data = text_test_withoutstop )\n",
    "\n",
    "Ytest_uni,clf1 = stochastic_descent(Uni_Tf_Tr, Y_train, Uni_Tf_Te)\n",
    "print('accuracy %s' % accuracy(Ytest_uni, Y_test))\n",
    "print(classification_report(Y_test, Ytest_uni,target_names=my_tags),\"\\n\\n\\n\")\n",
    "\n",
    "Ytest_uni,clf1 = naive_bayes(Uni_Tf_Tr, Y_train, Uni_Tf_Te)\n",
    "print('accuracy %s' % accuracy(Ytest_uni, Y_test))\n",
    "print(classification_report(Y_test, Ytest_uni,target_names=my_tags),\"\\n\\n\\n\")\n",
    "\n",
    "Ytest_uni,clf1 = Logistic(Uni_Tf_Tr, Y_train, Uni_Tf_Te)\n",
    "print('accuracy %s' % accuracy(Ytest_uni, Y_test))\n",
    "print(classification_report(Y_test, Ytest_uni,target_names=my_tags),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results For bigram with Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Bigram BOW with Tfidf -->\n",
      "\n",
      "SGD(Linear Support Vector Machine) Fitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD(Linear Support Vector Machine) Predicting\n",
      "accuracy 96.844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.98      0.96      0.97     25000\n",
      "         neg       0.96      0.98      0.97     25000\n",
      "\n",
      "    accuracy                           0.97     50000\n",
      "   macro avg       0.97      0.97      0.97     50000\n",
      "weighted avg       0.97      0.97      0.97     50000\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Naive Bayes Fitting\n",
      "SGD(Linear Support Vector Machine) Predicting\n",
      "accuracy 98.764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.99      0.99      0.99     25000\n",
      "         neg       0.99      0.98      0.99     25000\n",
      "\n",
      "    accuracy                           0.99     50000\n",
      "   macro avg       0.99      0.99      0.99     50000\n",
      "weighted avg       0.99      0.99      0.99     50000\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Logistic Fitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLogistic Predicting\n",
      "accuracy 98.764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.99      0.99      0.99     25000\n",
      "         neg       0.99      0.98      0.99     25000\n",
      "\n",
      "    accuracy                           0.99     50000\n",
      "   macro avg       0.99      0.99      0.99     50000\n",
      "weighted avg       0.99      0.99      0.99     50000\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"For Bigram BOW with Tfidf -->\\n\")\n",
    "Bi_Tf_Tr = Feature_extraction(grams = \"Bi\", tfidf = True,combined_data = full_text,data = text_train_withoutstop ) \n",
    "Bi_Tf_Te = Feature_extraction(grams = \"Bi\", tfidf = True,combined_data = full_text,data = text_test_withoutstop ) \n",
    "\n",
    "Ytest_bi,clf1 = stochastic_descent(Bi_Tf_Tr, Y_train, Bi_Tf_Te)\n",
    "print('accuracy %s' % accuracy(Ytest_bi, Y_test))\n",
    "print(classification_report(Y_test, Ytest_bi,target_names=my_tags),\"\\n\\n\\n\")\n",
    "\n",
    "Ytest_bi,clf1 = naive_bayes(Bi_Tf_Tr, Y_train, Bi_Tf_Te)\n",
    "print('accuracy %s' % accuracy(Ytest_bi, Y_test))\n",
    "print(classification_report(Y_test, Ytest_bi,target_names=my_tags),\"\\n\\n\\n\")\n",
    "\n",
    "Ytest_uni,clf1 = Logistic(Bi_Tf_Tr, Y_train, Bi_Tf_Te)\n",
    "print('accuracy %s' % accuracy(Ytest_bi, Y_test))\n",
    "print(classification_report(Y_test, Ytest_bi,target_names=my_tags),\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results For trigram with Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Trigram BOW with Tfidf -->\n",
      "\n",
      "SGD(Linear Support Vector Machine) Fitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD(Linear Support Vector Machine) Predicting\n",
      "accuracy 97.54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.98      0.97      0.98     25000\n",
      "         neg       0.97      0.98      0.98     25000\n",
      "\n",
      "    accuracy                           0.98     50000\n",
      "   macro avg       0.98      0.98      0.98     50000\n",
      "weighted avg       0.98      0.98      0.98     50000\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Naive Bayes Fitting\n",
      "SGD(Linear Support Vector Machine) Predicting\n",
      "accuracy 99.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       1.00      1.00      1.00     25000\n",
      "         neg       1.00      1.00      1.00     25000\n",
      "\n",
      "    accuracy                           1.00     50000\n",
      "   macro avg       1.00      1.00      1.00     50000\n",
      "weighted avg       1.00      1.00      1.00     50000\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Logistic Fitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\boltuzamaki\\anaconda3\\envs\\pose\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLogistic Predicting\n",
      "accuracy 97.348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.98      0.97      0.97     25000\n",
      "         neg       0.97      0.98      0.97     25000\n",
      "\n",
      "    accuracy                           0.97     50000\n",
      "   macro avg       0.97      0.97      0.97     50000\n",
      "weighted avg       0.97      0.97      0.97     50000\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"For Trigram BOW with Tfidf -->\\n\")\n",
    "Tri_Tf_Tr =Feature_extraction(grams = \"Tri\", tfidf = True,combined_data = full_text,data = text_train_withoutstop ) \n",
    "Tri_Tf_Te = Feature_extraction(grams = \"Tri\", tfidf = True,combined_data = full_text,data = text_test_withoutstop ) \n",
    "\n",
    "\n",
    "Ytest_tri,clf1 = stochastic_descent(Tri_Tf_Tr, Y_train, Tri_Tf_Te)\n",
    "print('accuracy %s' % accuracy(Ytest_tri, Y_test))\n",
    "print(classification_report(Y_test, Ytest_tri,target_names=my_tags),\"\\n\\n\\n\")\n",
    "\n",
    "Ytest_tri,clf1 = naive_bayes(Tri_Tf_Tr, Y_train, Tri_Tf_Te)\n",
    "print('accuracy %s' % accuracy(Ytest_tri, Y_test))\n",
    "print(classification_report(Y_test, Ytest_tri,target_names=my_tags),\"\\n\\n\\n\")\n",
    "\n",
    "Ytest_tri,clf1 = Logistic(Tri_Tf_Tr, Y_train, Tri_Tf_Te)\n",
    "print('accuracy %s' % accuracy(Ytest_tri, Y_test))\n",
    "print(classification_report(Y_test, Ytest_tri,target_names=my_tags),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test = [\"you are a fucking bad\",\"you are amazing\"]\n",
    "test = Feature_extraction(grams = \"Tri\", tfidf = True,combined_data = full_text,data = Test )\n",
    "clf1.predict(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
