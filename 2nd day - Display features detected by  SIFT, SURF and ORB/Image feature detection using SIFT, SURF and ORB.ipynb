{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display features detected by  SIFT, SURF and ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import cv2\n",
    "# Surf and Sift are under patient but orb is opensource\n",
    "\n",
    "def Surf_Sift_Orb(img_path, algo=None):\n",
    "    img = cv2.imread(img_path , cv2.IMREAD_GRAYSCALE)\n",
    "    if algo == \"SIFT\":\n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "        keypoints , descriptors = sift.detectAndCompute(img, None)\n",
    "        \n",
    "    if algo == \"SURF\":    \n",
    "        surf = cv2.xfeatures2d.SURF_create()\n",
    "        keypoints , descriptors = surf.detectAndCompute(img, None)\n",
    "\n",
    "    if algo == \"ORB\": \n",
    "        orb = cv2.ORB_create()\n",
    "        keypoints , descriptors = orb.detectAndCompute(img, None)\n",
    "    \n",
    "    img = cv2.drawKeypoints(img, keypoints, None)\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Surf_Sift_Orb('10.jpg', \"SIFT\")                     # fed path and algo here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute force feature matching b/w two image using SURF/ SIFT/ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def Brute_Matching(base_img_path, test_img_path, Number_of_matches, algo = None):\n",
    "    img1 = cv2.imread(base_img_path , cv2.IMREAD_GRAYSCALE)\n",
    "    img2 = cv2.imread(test_img_path , cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # ORB Detector\n",
    "    if algo == \"ORB\":\n",
    "        orb = cv2.ORB_create()\n",
    "        kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "        kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "        \n",
    "        # Brute force search\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n",
    "        matches = bf.match(des1, des2)\n",
    "        matches = sorted(matches, key = lambda x:x.distance)\n",
    "        for m in matches:\n",
    "            m.distance\n",
    "        matching_result = cv2.drawMatches(img1, kp1, img2, kp2, matches[:Number_of_matches], None) \n",
    "\n",
    "    # SIFT Detector\n",
    "    if algo == \"SIFT\":\n",
    "        sift= cv2.xfeatures2d.SIFT_create()\n",
    "        kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "        kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "        \n",
    "        # Brute force search\n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(des1,des2,k=2)\n",
    "        good = []\n",
    "        good_without_list = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.75 * n.distance:\n",
    "                good.append([m])\n",
    "                good_without_list.append(m)\n",
    "        matching_result = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good[0:Number_of_matches], None, flags=2)       \n",
    "\n",
    "    # SURF Detector\n",
    "    if algo == \"SURF\":\n",
    "        surf = cv2.xfeatures2d.SURF_create()\n",
    "        kp1, des1 = surf.detectAndCompute(img1, None)\n",
    "        kp2, des2 = surf.detectAndCompute(img2, None)\n",
    "        \n",
    "        # Brute force search\n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(des1,des2,k=2)\n",
    "        good = []\n",
    "        good_without_list = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.75 * n.distance:\n",
    "                good.append([m])\n",
    "                good_without_list.append(m)\n",
    "        matching_result = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good[0:Number_of_matches], None, flags=2)       \n",
    "    \n",
    "    matching_result = cv2.resize(matching_result, (1500, 1000),interpolation = cv2.INTER_NEAREST) \n",
    "    cv2.imshow(\"Img1\", img1)\n",
    "    cv2.imshow(\"Img2\", img2)\n",
    "    cv2.imshow(\"Matches Keypoints\", matching_result)\n",
    "   \n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brute_Matching(\"10.jpg\", \"11.jpg\",20, algo = \"SIFT\")   # Show the feature common in two image using above techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real time object detection using SIFT features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def Real_time(image,video_sourc = 0):                # video_sourc can be 0 (web cam) or any file path location\n",
    "    img = cv2.imread(image, cv2.IMREAD_GRAYSCALE)  # queryiamge\n",
    "    cap = cv2.VideoCapture(video_sourc)\n",
    "    # Features\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp_image, desc_image = sift.detectAndCompute(img, None)\n",
    "    # Feature matching\n",
    "    index_params = dict(algorithm=0, trees=5)\n",
    "    search_params = dict()\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    while cap.isOpened():\n",
    "        _, frame = cap.read()\n",
    "        grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # trainimage\n",
    "        kp_grayframe, desc_grayframe = sift.detectAndCompute(grayframe, None)\n",
    "        matches = flann.knnMatch(desc_image, desc_grayframe, k=2)\n",
    "        good_points = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.6 * n.distance:\n",
    "                good_points.append(m)\n",
    "        # img3 = cv2.drawMatches(img, kp_image, grayframe, kp_grayframe, good_points, grayframe)\n",
    "        # Homography\n",
    "        if len(good_points) > 10:\n",
    "            query_pts = np.float32([kp_image[m.queryIdx].pt for m in good_points]).reshape(-1, 1, 2)\n",
    "            train_pts = np.float32([kp_grayframe[m.trainIdx].pt for m in good_points]).reshape(-1, 1, 2)\n",
    "            matrix, mask = cv2.findHomography(query_pts, train_pts, cv2.RANSAC, 5.0)\n",
    "            matches_mask = mask.ravel().tolist()\n",
    "            # Perspective transform\n",
    "            h, w = img.shape\n",
    "            pts = np.float32([[0, 0], [0, h], [w, h], [w, 0]]).reshape(-1, 1, 2)\n",
    "            dst = cv2.perspectiveTransform(pts, matrix)\n",
    "            homography = cv2.polylines(frame, [np.int32(dst)], True, (255, 0, 0), 3)\n",
    "            cv2.imshow(\"Homography\", homography)\n",
    "        else:\n",
    "            cv2.imshow(\"Homography\", grayframe)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Real_time('10.JPG')                                         # In jupyter this mat sometime throw error so use python ide or spyder instead"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
